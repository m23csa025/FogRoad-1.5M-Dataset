# FogRoad-12MM : A Million-Frame Video Testbed for  Real-World Defogging

Adverse weather such as atmospheric fog continues to undermine the reliability of vision-based navigation and perception systems. However, progress is slowed by the shortage of large-scale in-the-wild datasets that capture the full complexity of real driving scenes. Existing resources are usually limited to single images, generated with fog machines, or rendered synthetically, conditions that differ markedly from everyday traffic environments. We present FogRoad-1.5M, a video-centric dataset containing more than 12 million high-resolution frames paired with their source clips. Data was collected with dashboard-mounted cameras on highways, urban roads, and rural trails under varied illumination during day, dusk, and night, and across multiple weather regimes spanning dry, light fog, dense fog, and rain. Each sequence is time-stamped and geographically diverse, offering long temporal context and a broad spectrum of traffic densities and scene layouts. To illustrate its value we benchmark several state-of-the-art defogging/dehazing networks using three widely adopted no-reference quality metrics, BRISQUE, NIQE and FADE, and showcase performance gaps that emerge only on authentic video footage. By combining scale on the order of millions of frames, authenticity through uncontrolled outdoor capture, and rich temporal information from complete videos rather than isolated frames, FogRoad-1.5M establishes a new standard testbed for research on image and video defogging, robust perception, and weather-aware autonomous driving.

